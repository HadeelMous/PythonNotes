{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "442553b9",
   "metadata": {},
   "source": [
    "---\n",
    "# Assignment Description\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c61bc4",
   "metadata": {},
   "source": [
    "In this notebook, we build a machine learning model to predict whether a user will stop making payments within the next three months, given a specific reference date.\n",
    "\n",
    "The analysis uses two datasets:\n",
    "\n",
    "- A user table containing one row per user with five user-level features.\n",
    "\n",
    "- A monthly payments table containing payment dates for each user.\n",
    "\n",
    "Users make payments monthly until they stop, and once a user stops paying, they never resume.\n",
    "\n",
    "The notebook covers the full modeling workflow:\n",
    "\n",
    "1- Loading and exploring the data\n",
    "\n",
    "2- Constructing a dataset for a given reference date (features and target per user)\n",
    "\n",
    "3- Splitting the data into training, validation, and test sets\n",
    "\n",
    "4- Training and evaluating a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea9807",
   "metadata": {},
   "source": [
    "---\n",
    "# 0. Load libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e204b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 0. Load libraries\n",
    "# =========================================\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9336dbf",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Load the two CSV files with the data\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799f7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 1. Load the two CSV files with the data\n",
    "# =========================================\n",
    "\n",
    "# 1.1 Load data\n",
    "users = read_csv(\"user_table.csv\")\n",
    "payments = read_csv(\"monthly_payments.csv\")\n",
    "\n",
    "# 1.2 Clean data\n",
    "payments[\"date\"] = pd.to_datetime(payments[\"date\"])\n",
    "payments = payments.sort_values(by=[\"date\", \"user_id\"])\n",
    "#if payments['payment'].value_counts()[1] == len(payments): del(payments['payment'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e624ddc",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Write a function that constructs a dataset \n",
    "---\n",
    "\n",
    "(corresponding to a feature vector and a target per user) for a given date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b4af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 2. Write a function that constructs a dataset \n",
    "# (corresponding to a feature vector and a target per user) \n",
    "# for a given date\n",
    "# =========================================================\n",
    "\n",
    "# 2.1 Preprocess payments data\n",
    "snapshots = payments[[\"user_id\", \"date\"]].copy()\n",
    "snapshots.rename(columns={\"date\": \"snapshot_date\"}, inplace=True)\n",
    "\n",
    "# 2.2 Labeling function\n",
    "# snapshot_date = snapshots['snapshot_date'][0]\n",
    "# user_id = snapshots['user_id'][0]\n",
    "def label_future_payments(payments, snapshot_date, user_id):\n",
    "    future_start = snapshot_date + pd.DateOffset(months=1)\n",
    "    future_end = snapshot_date + pd.DateOffset(months=3)\n",
    "\n",
    "    future_payments = payments[\n",
    "        (payments.user_id == user_id) &\n",
    "        (payments.date >= future_start) &\n",
    "        (payments.date <= future_end)\n",
    "    ]\n",
    "\n",
    "    # Expect 3 monthly payments\n",
    "    return int(len(future_payments) < 3)\n",
    "\n",
    "snapshots[\"y\"] = snapshots.apply(\n",
    "    lambda row: label_future_payments(\n",
    "        payments, row.snapshot_date, row.user_id\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data = snapshots.merge(users, on=\"user_id\", how=\"left\")\n",
    "\n",
    "\n",
    "# 2.3 Tenure and number of payments features\n",
    "# snapshot_date = snapshots['snapshot_date'][0]\n",
    "# user_id = snapshots['user_id'][0]\n",
    "def build_behavioral_features(payments, snapshot_date, user_id):\n",
    "    history = payments[\n",
    "        (payments.user_id == user_id) &\n",
    "        (payments.date < snapshot_date)\n",
    "    ].sort_values(\"date\")\n",
    "\n",
    "    if history.empty:\n",
    "        return pd.Series({\n",
    "            \"num_payments\": 0\n",
    "        })\n",
    "\n",
    "    tenure = (snapshot_date - history.date.min()).days / 30\n",
    "\n",
    "    return pd.Series({\n",
    "        \"num_payments\": len(history)\n",
    "    })\n",
    "\n",
    "behavioral = snapshots.apply(\n",
    "    lambda row: build_behavioral_features(\n",
    "        payments, row.snapshot_date, row.user_id\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data = pd.concat([data, behavioral], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5679670",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Construct a train, validation, and test dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3bb954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 3. Construct a train, validation, and test dataset\n",
    "# ==================================================\n",
    "\n",
    "# 3.1 Split into train, validation and test based on snapshot_date\n",
    "\"\"\" Note:\n",
    "# To evaluate the model in a realistic setting, the dataset is split\n",
    "# chronologically based on the snapshot_date. This avoids information\n",
    "# leakage from the future into the past, which would occur with random\n",
    "# splits or standard cross-validation.\n",
    "\n",
    "# The earliest 60% of snapshot dates are used for training, the next\n",
    "# 20% for validation (model selection), and the most recent 20% for\n",
    "# final testing. This setup simulates the real-world scenario where\n",
    "# models are trained on historical data and used to predict future\n",
    "# user behavior.\n",
    "\"\"\"\n",
    "\n",
    "cutoff_date_1 = data[\"snapshot_date\"].quantile(0.6)\n",
    "cutoff_date_2 = data[\"snapshot_date\"].quantile(0.8)\n",
    "\n",
    "train = data[data.snapshot_date <= cutoff_date_1]\n",
    "val = data[(data.snapshot_date > cutoff_date_1) & (data.snapshot_date <= cutoff_date_2)]\n",
    "test = data[(data.snapshot_date > cutoff_date_2)]\n",
    "\n",
    "X_train = train.drop(columns=[\"user_id\", \"snapshot_date\", \"y\"])\n",
    "Y_train = train[\"y\"]\n",
    "\n",
    "X_val = val.drop(columns=[\"user_id\", \"snapshot_date\", \"y\"])\n",
    "Y_val = val[\"y\"]\n",
    "\n",
    "X_test = test.drop(columns=[\"user_id\", \"snapshot_date\", \"y\"])\n",
    "Y_test = test[\"y\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62ae75",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Train and evaluate a model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487736d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR validation ROC-AUC: 0.6914\n",
      "DT validation ROC-AUC: 0.5992\n",
      "RF validation ROC-AUC: 0.6529\n",
      "Best model: LR\n",
      "Test ROC-AUC: 0.5542090760141853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Note:\\n# Performance improves when training on later snapshots because users close \\n# to churn exhibit more deterministic outcomes under the assumption of \\n# irreversible monthly churn.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================\n",
    "# 4. Train and evaluate a model\n",
    "# =============================\n",
    "\n",
    "# 4.1 Test options and evaluation metric\n",
    "scoring = 'roc_auc' \n",
    "\"\"\" Note:\n",
    "# ROC-AUC is used because the task focuses on ranking churn risk\n",
    "# rather than making binary decisions at a fixed threshold\n",
    "\"\"\"\n",
    "seed = 7\n",
    "\n",
    "# 4.2 Spot-Check Algorithms\n",
    "models = {}\n",
    "models['LR'] = LogisticRegression(random_state=seed)\n",
    "models['DT'] = DecisionTreeClassifier(random_state=seed)\n",
    "models['RF'] = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    score = roc_auc_score(Y_val, val_pred)\n",
    "    results[name] = score\n",
    "    print(f\"{name} validation ROC-AUC: {score:.4f}\")\n",
    "\n",
    "best_model_name = max(results, key=results.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(\"Best model:\", best_model_name)\n",
    "\n",
    "\n",
    "# 4.3 Final evaluation on test (only once)\n",
    "X_train_val = pd.concat([X_train, X_val]) # Note: retrain on train + val\n",
    "Y_train_val = pd.concat([Y_train, Y_val]) \n",
    "best_model.fit(X_train_val, Y_train_val)\n",
    "\n",
    "test_pred = best_model.predict_proba(X_test)[:, 1]\n",
    "test_auc = roc_auc_score(Y_test, test_pred)\n",
    "\n",
    "print(\"Test ROC-AUC:\", test_auc)\n",
    "# 0.5383776561198086 (only fit on train)\n",
    "# 0.5467572259423489 with tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4cb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4be08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stda_tax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
