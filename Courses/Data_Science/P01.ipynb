{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![link text](https://ph-files.imgix.net/069dd825-cddf-4048-adde-8e81396c2c68?auto=format)\n",
    "\n",
    "\n",
    "You will be working with datasets obtained through the [The Movie Database (TMDb) API](https://developers.themoviedb.org/3/getting-started/introduction). The first dataset is part of the MovieLens Latest Full Dataset, comprising 26 million ratings on 45.000 movies from 27.000 users. Let's look at the features in this dataset.\n",
    "\n",
    "**Features**\n",
    "\n",
    "* **adult**: Indicates if the movie is X-Rated.\n",
    "* **belongs_to_collection**: A stringified dictionary with info on the movie series a particular film belongs to (e.g.: Lord of the Rings).\n",
    "* **budget**: The movie budget in dollars.\n",
    "* **genres**: A stringified list of dictionaries describing all genres associated with the movie.\n",
    "* **homepage**: The movie's official homepage.\n",
    "* **id**: An identifier for the movie.\n",
    "* **imdb_id**: IMDB's identifier for the movie.\n",
    "* **original_language**: The language in which the movie was shot.\n",
    "* **original_title**: The original title of the movie.\n",
    "* **overview**: A brief text about the movie.\n",
    "* **popularity**: A Popularity Score given by TMDb.\n",
    "* **poster_path**: The URL of the poster image.\n",
    "* **production_companies**: A stringified list of production companies involved with making of the movie.\n",
    "* **production_countries**: A stringified list of countries in which the movie was produced.\n",
    "* **release_date**: Release date of the movie in theaters.\n",
    "* **revenue**: The total revenue of the movie in dollars.\n",
    "* **runtime**: The runtime of the movie in minutes.\n",
    "* **spoken_languages**: A stringified list of languages spoken in the film.\n",
    "* **status**: The status of the movie (Released, To Be Released, etc.)\n",
    "* **tagline**: The movie's tagline.\n",
    "* **title**: The official title of the movie.\n",
    "* **video**: Indicates whether there is a video of the movie in TMDb.\n",
    "* **vote_average**: The average rating of the movie, on a 0-10 scale.\n",
    "* **vote_count**: The number of votes by users, as counted by TMDb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "First, let's make sure to import Pandas and NumPy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Loading, preprocessing and cleaning the data (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the movie dataset from the following URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/movies_metadata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading and preprocessing the data (10 pts)\n",
    "\n",
    "Pandas infers a data type for raw data from a `.csv`, defaulting to string type when no other `dtype` could be established. For example, the `genres` column in our dataset is read as a string with a *stringified* list of dictionaries as cell content. \n",
    "\n",
    "Some preprocessing steps are therefore needed, to convert the columns into their proper data types.\n",
    "\n",
    "Write a function `load_movies_data()` that reads the URL into a Pandas DataFrame and preprocesses its columns to ensure that:\n",
    "\n",
    "1. Data in the `release_date` column consists of Pandas `Timestamp` objects, except for missing values. For example, executing a code cell with `df.release_date[0]` should display the output `Timestamp('1995-10-30 00:00:00')`.\n",
    "\n",
    "2. Data in `belongs_to_collection` consists of dictionaries, except for missing values.\n",
    "\n",
    "3. Data in `genres`, `production_companies` and `production_countries` consists of lists of dictionaries, except for missing values. \n",
    "\n",
    "For example, executing a code cell with `df.genres[0]` should display the output \n",
    "```\n",
    "[{'id': 16, 'name': 'Animation'},\n",
    " {'id': 35, 'name': 'Comedy'},\n",
    " {'id': 10751, 'name': 'Family'}]\n",
    "```\n",
    "which is a list type, not a string. The elements of the list are dictionaries (executing `df.genres[0][0]['name']` returns `'Animation'`). \n",
    "\n",
    "**Hint**: for items 2 and 3, you should use `ast.literal_eval`.\n",
    "\n",
    "These conversions can be performed using Pandas' built-in functions and/or calling Pandas' `apply()` with appropriate arguments. Avoid explicit looping. You'll be asked below to time the loading and preprocessing step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(url)\n",
    "data\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_cleaned = data.dropna()\n",
    "#data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from ast import literal_eval\n",
    "\n",
    "    \n",
    "\n",
    "def load_movies_data(url):\n",
    "    #date\n",
    "    parse_dates = ['release_date']\n",
    "    date_parser = lambda col : pd.to_datetime(col, errors='coerce') \n",
    "\n",
    "    # convert\n",
    "    \"\"\" func: convert to dict. \"\"\"\n",
    "    def convert_dic(val):\n",
    "        if val: return literal_eval(val)  # to safely evaluate strings as Python data structures.\n",
    "        else: return {}  \n",
    "\n",
    "    \"\"\" func: convert to list \"\"\"\n",
    "    def convert_lst(val):\n",
    "        if val: return literal_eval(val)\n",
    "        else: return []\n",
    "\n",
    "    \"\"\" converters \"\"\"\n",
    "    converters = {\n",
    "        'belongs_to_collection':convert_dic,\n",
    "        'genres':convert_lst,\n",
    "        'production_companies':convert_lst, \n",
    "        'production_countries':convert_lst,\n",
    "        }    \n",
    "\n",
    "    # mix col type \n",
    "    dtype = {'popularity' : 'str'}\n",
    " \n",
    "    # return\n",
    "    return pd.read_csv(\n",
    "                url, \n",
    "                engine = 'c',\n",
    "                parse_dates = parse_dates,\n",
    "                date_parser = date_parser,\n",
    "                converters = converters,\n",
    "                dtype = dtype,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call `load_movies_data()` and load the data into a DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "df = load_movies_data(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the DataFrame. You should check that it looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\"\"\" release_date \"\"\"\n",
    "# assert pd._libs.tslibs.timestamps.Timestamp == type(df.release_date[0])\n",
    "assert isinstance(df.release_date[0], pd.Timestamp)\n",
    "\n",
    "\"\"\" belongs_to_collection \"\"\"\n",
    "assert dict == type(df.belongs_to_collection[0])\n",
    "\n",
    "\"\"\" genres \"\"\"\n",
    "assert list == type(df.genres[0])\n",
    "assert dict == type(df.genres[0][0])\n",
    "\n",
    "\"\"\" production_countries \"\"\"\n",
    "assert list == type(df.production_countries[0])\n",
    "assert dict == type(df.production_countries[0][0])\n",
    "\n",
    "\"\"\" production_companies \"\"\"\n",
    "assert list == type(df.production_companies[0])\n",
    "assert dict == type(df.production_companies[0][0])\n",
    "\n",
    "\"\"\" head \"\"\"\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Timing your function (2.5 pts)\n",
    "\n",
    "Time the performance of your function. To get the points for this part, the time reported below must not exceed 40 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_time = %timeit -o -r 3 load_movies_data(url)\n",
    "print(\"Time (s):\", load_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Cleaning the data (2.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter/drop all rows in `df` meeting any of these conditions:\n",
    "* The `adult` value is not `'False'`\n",
    "* The `vote_count` value is missing\n",
    "* The `vote_average` value is missing\n",
    "\n",
    "Do not loop over rows to perform these checks. Use Pandas' built-in functionality to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "df = df[(\n",
    "    (df['adult'] == 'False') & \n",
    "    (df['vote_count'].notnull()) & \n",
    "    (df['vote_average'].notnull())\n",
    "    )].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Computing IMDb's ratings (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Top Rated 250 titles in IMDb are calculated using [a formula](https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV#calculatetop) that takes into account the number of votes that a title has received, the minimum votes required to be on the list, and the mean vote for all titles. The rating for a title is given as follows:\n",
    "\n",
    "$$ \\text{weighted rating } = \\left(\\frac{v}{v+m} \\cdot R\\right) + \\left(\\frac{m}{v+m} \\cdot C\\right)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$m$ = the minimum number of votes required to be listed in the Top Rated ranking. We'll let $m=1000$.\n",
    "\n",
    "$v$ = the number of votes received by the title (the title's **`vote_count`** value)\n",
    "\n",
    "$R$ = the average rating for the title (the title's **`vote_average`** value)\n",
    "\n",
    "$C$ = the mean vote across the whole list (the mean over the **`vote_average`** column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to compute the ratings for movies that could be listed in IMDb's Top Rated 250 ranking.  We want to do this as efficiently as possible. As a baseline for benchmarking, we'll use an approach that explicitly loops and indexes over the rows of the dataset and computes the weighted rating for the corresponding movie (if the movie has more than 1000 votes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = df['vote_average'].mean()\n",
    "m = 1000\n",
    "\n",
    "def weighted_rating(row):\n",
    "    if row['vote_count'] > m:\n",
    "        v = row['vote_count']\n",
    "        R = row['vote_average']\n",
    "        return (v/(v+m) * R) + (m/(v+m) * C)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def weighted_rating_loop(df):\n",
    "    rating_list = []\n",
    "    for i in range(len(df)):\n",
    "        rating = weighted_rating(df.iloc[i])\n",
    "        rating_list.append(rating)\n",
    "    df['imdb_rating'] = rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_rating_loop(df)\n",
    "\n",
    "columns_to_show = ['id', 'original_title'] + \\\n",
    "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the average performance of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_time = %timeit -r 3 -o weighted_rating_loop(df)\n",
    "print(\"Best time:\", basic_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remaining parts of the exercise, you are going to be asked to come up with alternative ways to compute the ratings, using various methodologies. Let's create a score board to keep track of performance. Here's a description of the rows:\n",
    "\n",
    "*   **Best single run time (s)**:  The best time used by your solution, in seconds.\n",
    "*   **Marginal performance improvement**: The time improvement of your current solution over its immediately preceding solution. Given by: $\\frac{\\text{best single run time (s) of previous solution}}{\\text{best single run time (s) of current solution}}$\n",
    "*   **Performance improvement over basic looping**:  The time improvement over our baseline solution. Given by: $\\frac{\\text{best single run time (s) of weighted_rating_loop}}{\\text{best single run time (s) of current solution}}$\n",
    "*   **Best single run time (s, teacher)**: The time of a solution provided by the teacher. \n",
    "*   **Marginal performance improvement (teacher)**: The time improvement of the teacher's solution over its immediately preceding solution. \n",
    "*   **Performance improvement over basic looping (teacher)**:  The teacher's solution improvement over the baseline solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data = {\n",
    "    'Best single run time (s)': [basic_time.best, np.nan, np.nan, np.nan,np.nan],\n",
    "    'Marginal performance improvement': [np.nan,np.nan, np.nan, np.nan,np.nan],\n",
    "    'Performance improvement over basic looping': np.nan,\n",
    "    'Best single run time (s, teacher)': [9.37, 3.87, 0.562, 0.0054, 0.00084],\n",
    "    'Marginal performance improvement (teacher)': [np.nan, 'x2.42', 'x6.88', 'x103.8', 'x6.45'],\n",
    "    'Performance improvement over basic looping (teacher)': [np.nan, 'x2.42', 'x16.69', 'x1732.17','x11172.98']\n",
    "}\n",
    "\n",
    "indices = ['Basic looping', 'Iterrows looping', 'apply()', 'Pandas vectorisation', 'NumPy vectorisation']\n",
    "timings = pd.DataFrame(timing_data, index=indices)\n",
    "timings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The grading for the following parts works as follows.**\n",
    "\n",
    "Let $m$ be the marginal performance improvement for the teacher's solution over basic looping, and let $m'$ be the marginal performance improvement for your solution over `basic_time`. If a part gives $n$ points, then you will get the $n$ points if $m' \\geq 0.4 m$, and 0 points otherwise.\n",
    "\n",
    "You don't get extra points for performing faster than the teacher's solution. But this is of course possible and you should feel free to optimise away as much as you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Looping with `iterrows` (2.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function `weighted_rating_iterrows(df)` that computes the ratings by looping over rows with the built-in iterator `iterrows`, and stores the results in a new column of the DataFrame called called `imdb_rating_iter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\n",
    "def weighted_rating_iterrows(df):\n",
    "    rating_list = np.full(df.shape[0], fill_value=np.nan)\n",
    "    for i, row in df.iterrows():\n",
    "        rating_list[i] = weighted_rating(row)\n",
    "    df['imdb_rating_iter'] = rating_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function and make sure that it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_rating_iterrows(df)\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    df.imdb_rating, df.imdb_rating_iter, check_names=False\n",
    ")\n",
    "\n",
    "columns_to_show = ['id', 'original_title'] + \\\n",
    "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the performance of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterrows_time = %timeit -r 3 -o weighted_rating_iterrows(df)\n",
    "print(\"Best time:\", iterrows_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Using `apply()`. (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function `weighted_rating_apply(df)` that computes the ratings using Pandas' `apply()` function, and stores the results in a new column of the DataFrame called `imdb_rating_apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "def weighted_rating_apply(df):\n",
    "    df['imdb_rating_apply'] = df.apply(lambda row : weighted_rating(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function and make sure that it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_rating_apply(df)\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    df.imdb_rating, df.imdb_rating_apply, check_names=False\n",
    ")\n",
    "\n",
    "columns_to_show = ['id', 'original_title'] + \\\n",
    "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the performance of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_time = %timeit -r 3 -o weighted_rating_apply(df)\n",
    "print(\"Best time:\", apply_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Vectorised solution with Pandas (12.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find a vectorised solution using Pandas. You have to define a function `weighted_rating_pandas(df)` that computes the ratings in a vectorised way and stores them in a new column of the DataFrame called `imdb_rating_pandas`. Use Pandas operations only: don't transform your data into NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_rating_pandas(df):\n",
    "    vR = df[['vote_count', 'vote_average']][df['vote_count']>m]\n",
    "    v = vR['vote_count']\n",
    "    R = vR['vote_average']\n",
    "    df['imdb_rating_pandas']= (v/(v+m) * R) + (m/(v+m) * C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function and make sure it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_rating_pandas(df)\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    df.imdb_rating, df.imdb_rating_pandas, check_names=False\n",
    ")\n",
    "\n",
    "columns_to_show = ['id', 'original_title'] + \\\n",
    "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the performance of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_time = %timeit -r 3 -o weighted_rating_pandas(df)\n",
    "print(\"Best time:\", pandas_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Vectorised solution with NumPy (12.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find a vectorised solution that uses NumPy to speed up the calculations. You have to define a function `weighted_rating_numpy(df)` that computes the ratings in a vectorised way and stores them in a new column of the DataFrame called `imdb_rating_numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "def weighted_rating_numpy(df):\n",
    "    v = df['vote_count'].to_numpy(dtype='float64')\n",
    "    R = df['vote_average'].to_numpy(dtype='float64')\n",
    "    score = (v/(v+m) * R) + (m/(v+m) * C)\n",
    "    score = np.where(v > m, score, np.nan)\n",
    "    df['imdb_rating_numpy'] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function and make sure it works as intended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_rating_numpy(df)\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    df.imdb_rating, df.imdb_rating_numpy, check_names=False\n",
    ")\n",
    "\n",
    "columns_to_show = ['id', 'original_title'] + \\\n",
    "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Find out the top 25 titles (2.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the top 25 titles? Now that we have the IMDb ratings conveniently stored in a column, display the top 25 titles, together with their IMDb rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# ascending=False means sorting in descending order (from highest to lowest).\n",
    "# axis=0 means sorting along the rows \n",
    "# in large dataset 'mergesort' is faster than the deafult 'quicksort'\n",
    "df[['title', 'imdb_rating']].sort_values(by='imdb_rating', ascending=False, axis=0, kind='mergesort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Predicting the genre of movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you'll be asked to create a number of features and use them to predict whether a movie is a science fiction movie or not. \n",
    "For this classification task, we'll work with a different part of the movies dataset, which contains more information for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Adding binary features for genres (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Exercise 1, the data on several columns is in a stringified format. Pre-process the following columns appropriately, as you did with the `genres` column in Part 1 of Exercise 1.\n",
    "```\n",
    "'belongs_to_collection', 'genres', 'production_companies','production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew'\n",
    "```\n",
    " \n",
    "Don't loop explicitly over the rows to perform this preprocessing. Your dataframe should be named `train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df= pd.read_csv(train_url)\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from ast import literal_eval\n",
    "\n",
    "def load_movies_data(url):\n",
    "    #date\n",
    "    parse_dates = ['release_date']\n",
    "    date_parser = lambda col : pd.to_datetime(col, errors='coerce') \n",
    "\n",
    "    # convert\n",
    "    \"\"\" func: convert to dict. \"\"\"\n",
    "    def convert_dic(val):\n",
    "        if val: #return literal_eval(val)\n",
    "            try: return literal_eval(val)\n",
    "            except:return {} \n",
    "        else: return {}  \n",
    "\n",
    "    \"\"\" func: convert to list \"\"\"\n",
    "    def convert_lst(val):\n",
    "        if val: #return literal_eval(val)\n",
    "             try: return literal_eval(val)\n",
    "             except:return []\n",
    "        else: return []\n",
    "\n",
    "    \"\"\" converters \"\"\"\n",
    "    converters = {\n",
    "        'belongs_to_collection':convert_dic,\n",
    "        'genres':convert_lst,\n",
    "        'production_companies':convert_lst, \n",
    "        'production_countries':convert_lst,\n",
    "        'spoken_languages': convert_lst,\n",
    "        'Keywords': convert_lst, \n",
    "        'cast': convert_lst, \n",
    "        'crew': convert_lst,\n",
    "        }    \n",
    "    \n",
    "\n",
    " \n",
    "    # return\n",
    "    return pd.read_csv(\n",
    "                url, \n",
    "                engine = 'c',\n",
    "                parse_dates = parse_dates,\n",
    "                date_parser = date_parser,\n",
    "                converters = converters,\n",
    "                )\n",
    "\n",
    "train= load_movies_data(train_url)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the 'genres' column, you can see that movies have a varying number of associated genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['genres'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will work only if you've already preprocessed the genres' column into lists of dicts\n",
    "for i, v in enumerate(train.genres.head()):\n",
    "    print(i, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of movies that have $n$ associated genres, for each $n$ in the dataset. If a movie has no associated genres, assign it the number 0. \n",
    "\n",
    "You have to use Pandas built-in functions only (no explicit looping). For example, you could use `apply()` with an appropriate function to apply to each row. \n",
    "\n",
    "Once you have the counts, visualise them as a bar chart, with one bar per possible number of associated genres, and the height of the bar representing the number of movies with that number of genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# genre counts freq\n",
    "genre_counts = train['genres'].apply(lambda val: len(val))\n",
    "genre_counts_freq = genre_counts.value_counts()\n",
    "\n",
    "# Bar chart\n",
    "plt.bar(genre_counts_freq.index, genre_counts_freq.values, color= 'g')\n",
    "plt.xlabel('Number of Genres')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.title('Bar chart: Number of Movies vs Number of Genres')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our binary features next. Complete the following steps:\n",
    " \n",
    "1.   Transform the `genres` column by replacing its current entries with the list of names of genres occurring in the entries.  For example, the entry \n",
    "```\n",
    "[{'id': 10749, 'name': 'Romance'}, {'id': 35, 'name': 'Comedy'}]\n",
    "```\n",
    "should be transformed into:\n",
    "```\n",
    "['Romance','Comedy']\n",
    "```\n",
    "Empty entries should be transformed into the empty list `[]`.\n",
    "\n",
    "2. Create a separate column (in `train`) for each of the 20 genres, with name `genres_(nameofgenre)` (e.g. `genres_Comedy`). A movie should have a 1 on a genres column if the genre is one of the associated genres for that movie, and a 0 otherwise.\n",
    "    * To get started, consider what operations create a data frame with dimensions as `train` and columns as specified here, based on the list output from step 1. Then combine this data frame with `train`.\n",
    "\n",
    "You have to use Pandas built-in functions only (no explicit looping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\n",
    "# Generalized func to one hot encode list features\n",
    "def one_hot_encoding_list(feature):\n",
    "\n",
    "    # Transfer feature column to list of names of feature occurring in the entries\n",
    "    try:\n",
    "        train[feature] = train[feature].apply(lambda lst: list(map(lambda dic: dic['name'], lst)))\n",
    "    except:\n",
    "        print(f'UserWarning:\\n\"{feature}\" feature is already transferred.')\n",
    "        return False\n",
    "\n",
    "    # Number of most common classes to conseder within a feature  \n",
    "    N = 20 if feature == 'genres' else 30\n",
    "    \n",
    "    # Most common classes to conseder within a feature \n",
    "    classes = train[feature].explode(feature).value_counts().index[0:N].tolist()\n",
    "    \n",
    "    # func to create a binary feature for each class 1 if exist 0 otherwise\n",
    "    def insert_binary_col(nameofclass):\n",
    "        train.insert(\n",
    "                len(train.columns), \n",
    "                feature + '_' + nameofclass, \n",
    "                train[feature].apply(lambda lst: 1 if nameofclass in lst else 0)\n",
    "                )\n",
    "        return True\n",
    "\n",
    "    # map insert_binary_col func on most common classes list\n",
    "    list(map(insert_binary_col, classes))\n",
    "\n",
    "    # Return True if everything is ok\n",
    "    return True\n",
    "\n",
    "# genres feature one hot encoding \n",
    "one_hot_encoding_list(feature='genres')\n",
    "\n",
    "# Check\n",
    "train.iloc[:,23:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# genre freq.\n",
    "genre_freq = train['genres'].explode('genres').value_counts()\n",
    "\n",
    "# Bar chart\n",
    "plt.bar(genre_freq.index, genre_freq.values, color= 'g')\n",
    "plt.xlabel('Genres')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.title('Bar chart: Number of Movies vs Genres')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Adding more binary features (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've now extracted binary features for all genres associated with a movie. But there's other information that we could use to base our predictions on. \n",
    "\n",
    "The `genres` column is just one out of several columns containing lists of dictionaries as entries. For example, the `production_companies` column also contains lists of dictionaries, providing names of the companies producing the movie. As you just did with genres, add new columns for:\n",
    " \n",
    "1.   The names of the 30 most common production companies\n",
    "2.   The names of the 30 most common production countries\n",
    "3.   The names of the 30 most common actors (`cast` column) \n",
    "4.   The names of the 30 most common crew members\n",
    "5.   The names of the 30 most common keywords\n",
    " \n",
    "We recommend you generalize the functionality implemented in the previous question (e.g. to other columns and to restrict to top 30 most common values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\n",
    "# selected features\n",
    "features = ['production_companies', 'production_countries', 'Keywords', 'cast', 'crew']\n",
    "\n",
    "# map the generalized function \"one_hot_encoding_list(feature)\" on the selected features list\"\n",
    "list(map(one_hot_encoding_list, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result. You should now have a much wider table, with the new columns consisting of binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Part 3: Adding numerical date features (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create some features based on the release date information. Create a new column storing the value for each of the following  aspects of a release date:\n",
    " \n",
    "```\n",
    "['year', 'weekday', 'month', 'weekofyear', 'day', 'quarter']\n",
    "```\n",
    " \n",
    "As usual, don't iterate explicitly to create these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# Add 'day' feature\n",
    "train['day'] = train['release_date'].dt.day\n",
    "\n",
    "# Add 'month' feature \n",
    "train['month'] = train['release_date'].dt.month\n",
    "\n",
    "# Add 'year' feature\n",
    "train['year'] = train['release_date'].dt.year\n",
    "\n",
    "# Add 'weekday' feature: with Monday=0, Sunday=6\n",
    "train['weekday'] = train['release_date'].dt.dayofweek \n",
    "\n",
    "# Add 'weekofyear' feature \n",
    "train['weekofyear'] = train['release_date'].dt.weekofyear\n",
    "\n",
    "# Add 'quarter' feature \n",
    "train['quarter'] = train['release_date'].dt.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll drop the columns that will not be used for learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['id', 'homepage', 'original_language',\n",
    "                    'title', 'imdb_id','crew', 'poster_path', \n",
    "                    'release_date', 'status', 'belongs_to_collection',\n",
    "                    'Keywords', 'original_title', 'overview',\n",
    "                    'production_companies', 'production_countries', \n",
    "                    'spoken_languages', 'tagline', 'cast','genres'], \n",
    "                   axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, drop any rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "train = train.dropna()\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Prediction (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the necessary `sklearn` libraries and prepare the training data for learning. Recall that your goal is to predict whether a movie has science fiction as an associated genre. So you're dealing with a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sklearn` to prepare the training and test sets, setting aside 15% of the data for testing. Call the training input features, training labels, test input features and test labels as follows:\n",
    "\n",
    "```\n",
    "x_train, x_test, y_train, y_test\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# Split-out X,y datasets\n",
    "\n",
    "# Selects all columns in the train DataFrame except the column 'genres_Science Fiction'\n",
    "X = train.loc[:, train.columns != 'genres_Science Fiction'].to_numpy()\n",
    "y = train.loc[:,'genres_Science Fiction'].to_numpy()\n",
    "\n",
    "# Set up seed and test size\n",
    "seed = 174360\n",
    "test_size = 0.15  \n",
    "\n",
    "# Split-out train, test datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = seed, stratify = y)\n",
    "print (f'{len(y_train)} samples to train.')\n",
    "print (f'{len(y_test)} to test the final model on (unseen data).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance). Run the following code to feature scale your input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler() # standardize the training and testing datasets.\n",
    "scaler.fit(x_train)  #Calculates the mean and standard deviation for each feature in the training data\n",
    "x_train = scaler.transform(x_train) # Transforms the training data using the previously computed mean and standard deviation\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the shape of your data looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier of your choice. Then report results:\n",
    "* Display the confusion matrix over the test set in absolute numbers.\n",
    "    * These numbers reflect number of true positives, true negatives, false positives and false negatives.\n",
    "* Display a normalized confusion matrix over the test set, so [sensitivity and specificity](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers) can be read from the diagonal (off-diagonal will contain type I and type II error rates).\n",
    "    * Note that sensitivity is recall for the positive class (1), whereas specificity is recall for the negative class (0).\n",
    "* State **in free-text** the sensitivity and specificity of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# =============== Libraries\n",
    "\"\"\" for models \"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\"\"\" for model selection cv \"\"\" \n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\"\"\" for Reporting metrics \"\"\"\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\"\"\" printing \"\"\"\n",
    "def pprint(iter):\n",
    "    if type(iter) == dict : \n",
    "        for item in iter.items(): print('\\t', item)\n",
    "    elif type(iter) == list:\n",
    "        for item in iter: print('\\t', item)\n",
    "    else:\n",
    "        try: print(iter)\n",
    "        except: raise Exception\n",
    "\n",
    "\n",
    "# =============== Tuning: Logistic Regression\n",
    "\"\"\" scoring \"\"\"\n",
    "scoring = 'f1'\n",
    "\n",
    "\"\"\" define model \"\"\"\n",
    "model = LogisticRegression()\n",
    "\n",
    "\"\"\" define grid \"\"\"\n",
    "grid = dict()\n",
    "grid['class_weight'] = ['balanced']      # Weights associated with classes in the form.\n",
    "grid['solver'] = ['liblinear', 'saga']   # Algorithm to use in the optimization problem.\n",
    "grid['penalty'] = ['l1', 'elasticnet']   # Regularization method; The norm used in the penalization\n",
    "grid['C'] = [100, 10, 1.0, 0.1, 0.01]    # Inverse of regularization strength; must be a positive float. smaller values specify stronger regularization.\n",
    "\n",
    "\"\"\" define model evaluation method \"\"\"\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=seed)\n",
    "\n",
    "\"\"\" define search \"\"\"\n",
    "search = GridSearchCV(estimator = model, param_grid = grid, scoring=scoring, cv=cv, n_jobs = -1, verbose = 2)\n",
    "\n",
    "\"\"\" perform the search \"\"\"\n",
    "results = search.fit(x_train, y_train)\n",
    "\n",
    "\"\"\" summarize \"\"\"\n",
    "print(f\"Best {scoring} score: {np.round(results.best_score_,2)} ({np.round(results.cv_results_['std_test_score'][results.best_index_],2)})\")\n",
    "print(\"Using:\") \n",
    "pprint(results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Final model:\n",
    "\"\"\" define and fit final model \"\"\"\n",
    "model = LogisticRegression(**results.best_params_)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# =============== Report:\n",
    "\"\"\" Confusion Matrix \"\"\"\n",
    "disp = plot_confusion_matrix(model, x_test, y_test, cmap=plt.cm.Blues, normalize=None, include_values= True)  \n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\"\"\" Normalized Confusion Matrix \"\"\"\n",
    "disp = plot_confusion_matrix(model, x_test, y_test, cmap=plt.cm.Blues, normalize='true', include_values= True)  \n",
    "disp.ax_.set_title('Normalized Confusion Matrix')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\"\"\" Sensitivity & Specificity \"\"\"\n",
    "predictions = model.predict(x_test)\n",
    "print('Sensitivity: %.3f' % recall_score(y_test, predictions, average='binary', pos_label = 1))\n",
    "print('Specificity: %.3f' % recall_score(y_test, predictions, average='binary', pos_label = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your explanation here*\n",
    "\n",
    "**Split data for Learning:**\n",
    "- 85% cross-validation set (to train the model). \n",
    "- 15% test set (to validate the final model, unseen data).\n",
    "- Stratified split since we want the two sets above to have the same labels distribution. \n",
    "\n",
    "**Evaluation Metric:**\n",
    "- We chose the f1 score because it evenly weights precision and recall and is the most commonly used option when learning from unbalanced data like the one we have.\n",
    "\n",
    "**Model Selection:**  \n",
    "Because it provides a linear decision boundary, has a few assumptions, and is a solid baseline model for a binary classification task, we selected to tune a *logistic regression model*. We utilized *Cross-Validation* with stratified splits to determine the optimal parameter combinations (best model) because we want the training and test data of each CV fold to have the same labels distribution.\n",
    "\n",
    "**Best Model:**  \n",
    "Weighted logistic regression with L1-regularization(Lasso) was the best model. Which makes sense because: weighted inputs help deal with the problem of having unbalanced data, and L1-regularization aids feature selection by removing non-essential characteristics. When there are a lot of feature points, this is quite useful.\n",
    "\n",
    "\n",
    "\n",
    "**Report results:**\n",
    "The final model givis on the test (unseendata):\n",
    "- *Sensitivity = 0.773*\n",
    "- *Specificity = 0.791*  \n",
    "\n",
    "which good a good tradoff between both Sensitivity and Specificity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Prediction with less leakage (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Wikipedia, [data leakage](https://en.wikipedia.org/wiki/Leakage_(machine_learning)) is the use of information in the model training process which would not be expected to be available at prediction time, causing the predictive scores (metrics) to overestimate the model's utility when run in a production environment.\n",
    "\n",
    "Feature or column-wise leakage is caused by the inclusion of columns which are one of the following: a duplicate label, a proxy for the label, or the label itself\n",
    "\n",
    "Considering we're doing binary classification of whether a movie is science fiction, identify the most prominent cause of feature leakage among the features added during Exercise 3. \n",
    "\n",
    "1) **Argue** for your choice, 2) train a classifier not subject to this feature leakage (it's OK to create a new train/test split) and 3) **report the results** as you did in Part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your explanation here*\n",
    "\n",
    "The most prominent cause of feature leakage among the features added during Exercise 3 are: \n",
    "- She added numerical features based on the release date information.\n",
    "- Some of the extracted binary features for all crews associated with a movie.\n",
    "\n",
    "The following pairs of features are verified, see code below, to be highly corrlated with (|cor.| > 0.75):\n",
    "- month, weekofyear \n",
    "- month, quarter\n",
    "- weekofyear, quarter\n",
    "- crew_Janet Hirshenson, crew_Jane Jenkins\n",
    "- crew_Bob Weinstein, crew_Harvey Weinstein\n",
    "- crew_Deborah Aquila, crew_Tricia Wood\n",
    "- production_companies_Working Title Films, crew_Tim Bevan\n",
    "\n",
    "Each feature, from the aforementioned highly corrlated pair of features, seems to have a proxy wich introduce feature or column-wise leakage. \n",
    "\n",
    "To deal with feature or column-wise leakage, we can *delete some proxies* Like quarter, weekofyear and keep month. We can also keep one of the features from the other pair of features in the aforementioned list while deleting one. Moreover, using *L1-regularization* helps in feature selection by removing non-essential feature, this is quite useful.\n",
    "\n",
    "\n",
    "**In the below implementation (code):**  \n",
    "We take a similar strategy to the first implementation, except that we remove one feature from each highly correlated pair of features.\n",
    "\n",
    "*Report results:*  \n",
    "The final model givis on the test (unseendata):\n",
    "- *Sensitivity = 0.773*\n",
    "- *Specificity = 0.803*\n",
    "\n",
    "\n",
    "\n",
    "Not so much improvment, The Specificity has increased slightly here, due to the fact that the final model in the first implementation, like this one, used *L1-regularization*, which aids in feature selection by removing non-essential features (for example, proxy), and this was also dealing with feature or column-wise leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# ===============  Correlation\n",
    "\"\"\" set threshold \"\"\"\n",
    "threshold = 0.75\n",
    "\n",
    "\"\"\" corr matrix \"\"\"\n",
    "corr_matrix = np.corrcoef(train.to_numpy(),rowvar=False)\n",
    "\n",
    "\"\"\" mask corr. matrix magnitude > threshold \"\"\" \n",
    "mask = np.round(abs(corr_matrix),2) > threshold\n",
    "\n",
    "\"\"\" diagonal not considered \"\"\"\n",
    "np.fill_diagonal(mask,False)\n",
    "\n",
    "\"\"\" find indices high corr. features \"\"\"\n",
    "mask_true_indices = np.where(mask==True)\n",
    "zipped = zip(mask_true_indices[0], mask_true_indices[1])\n",
    "high_corr_indices = sorted(list(set(map(tuple,map(sorted,zipped)))))\n",
    "\n",
    "def to_col_names(tup, features_names = train.columns):    \n",
    "    return f'({features_names[tup[0]]}, {features_names[tup[1]]}) with corr = {np.round(corr_matrix[tup[0],tup[1]],2)}'\n",
    "\n",
    "print(f'The following features has |Correlation| > {threshold}:')\n",
    "pprint(list(map(to_col_names, high_corr_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Datasets:\n",
    "\"\"\" new dataset \"\"\"\n",
    "train_new = train.copy()\n",
    "del(train_new['month'])\n",
    "del(train_new['quarter'])\n",
    "del(train_new['production_companies_Working Title Films'])\n",
    "del(train_new['crew_Deborah Aquila'])\n",
    "del(train_new['crew_Harvey Weinstein'])\n",
    "del(train_new['crew_Janet Hirshenson'])\n",
    "\n",
    "\"\"\" Split X,y \"\"\"\n",
    "X = train_new.loc[:, train_new.columns != 'genres_Science Fiction'].to_numpy()\n",
    "y = train_new.loc[:,'genres_Science Fiction'].to_numpy()\n",
    "\n",
    "\"\"\" Split train, test \"\"\"\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = seed, stratify = y)\n",
    "\n",
    "\n",
    "# =============== Tuning: Logistic Regression\n",
    "\"\"\" scoring \"\"\"\n",
    "scoring = 'f1'\n",
    "\n",
    "\"\"\" define model \"\"\"\n",
    "model = LogisticRegression()\n",
    "\n",
    "\"\"\" define grid \"\"\"\n",
    "grid = dict()\n",
    "grid['class_weight'] = ['balanced']      # Weights associated with classes in the form.\n",
    "grid['solver'] = ['liblinear', 'saga']   # Algorithm to use in the optimization problem.\n",
    "grid['penalty'] = ['l1', 'elasticnet']   # Regularization method; The norm used in the penalization\n",
    "grid['C'] = [100, 10, 1.0, 0.1, 0.01]    # Inverse of regularization strength; must be a positive float. smaller values specify stronger regularization.\n",
    "\n",
    "\"\"\" define model evaluation method \"\"\"\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=seed)\n",
    "\n",
    "\"\"\" define search \"\"\"\n",
    "search = GridSearchCV(estimator = model, param_grid = grid, scoring=scoring, cv=cv, n_jobs = -1, verbose = 2)\n",
    "\n",
    "\"\"\" perform the search \"\"\"\n",
    "results = search.fit(x_train, y_train)\n",
    "\n",
    "\"\"\" summarize \"\"\"\n",
    "print(f\"Best {scoring} score: {np.round(results.best_score_,2)} ({np.round(results.cv_results_['std_test_score'][results.best_index_],2)})\")\n",
    "print(\"Using:\") \n",
    "pprint(results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Final model:\n",
    "\"\"\" define and fit final model \"\"\"\n",
    "model = LogisticRegression(**results.best_params_)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# =============== Report:\n",
    "\"\"\" Confusion Matrix \"\"\"\n",
    "disp = plot_confusion_matrix(model, x_test, y_test, cmap=plt.cm.Blues, normalize=None, include_values= True)  \n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\"\"\" Normalized Confusion Matrix \"\"\"\n",
    "disp = plot_confusion_matrix(model, x_test, y_test, cmap=plt.cm.Blues, normalize='true', include_values= True)  \n",
    "disp.ax_.set_title('Normalized Confusion Matrix')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\"\"\" Sensitivity & Specificity \"\"\"\n",
    "predictions = model.predict(x_test)\n",
    "print('Sensitivity: %.3f' % recall_score(y_test, predictions, average='binary', pos_label = 1))\n",
    "print('Specificity: %.3f' % recall_score(y_test, predictions, average='binary', pos_label = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Basic movie recommendation system (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you'll build a simple movie recommendation system.  The system will take a movie as input and recommend a list of similar movies. In order to recommend similar movies, you will use the correlation between the ratings of movies as a similarity metric. We'll use Pearson's correlation. \n",
    " \n",
    "The data for this exercise is available in the following URLs. It contains basic info about movies, as well as ratings provided by several users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/ratings.csv'\n",
    "url2 = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/movies.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preparing the ratings data (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from these two URLs, and create a single dataframe from them, with the following columns:\n",
    "\n",
    "| userId | movieId | rating | timestamp | title | genres |\n",
    "|--------|---------|--------|-----------|-------|--------|\n",
    "|        |         |        |           |       |        |\n",
    "\n",
    "Call the dataframe `movie_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\"\"\" load datasets \"\"\"\n",
    "ratings = pd.read_csv(url1)\n",
    "movies  = pd.read_csv(url2)\n",
    "movie_data = pd.merge(ratings, movies, how = 'inner', on = 'movieId')\n",
    "display(movie_data.head(10))\n",
    "\n",
    "\"\"\" free memory \"\"\"\n",
    "del(ratings, movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the correlation between the ratings of movies, create a dataframe where each column is a movie name and each row contains the rating assigned by a specific user to that movie. \n",
    "\n",
    "You'll notice that this dataframe has many NaN values, since each movie is not rated by every user. Call the dataframe `user_ratings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\"\"\" define user_ratings \"\"\"\n",
    "user_ratings = movie_data[['userId', 'rating', 'title']].pivot_table(index='userId', columns='title', values='rating')\n",
    "display(user_ratings.head(10))\n",
    "\n",
    "\"\"\" free memory \"\"\"\n",
    "del(movie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Finding the most similar movies (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column contains all the user ratings for a particular movie. Let's take the user ratings for the movie Toy Story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings['Toy Story (1995)'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, find the correlation between the user ratings for Toy Story and the user ratings of all other movies. \n",
    " \n",
    "More specifically, create a dataframe that contains two columns, called `title` and `Correlation`. Each row should contain a movie title $x$, followed by the pairwise correlation between the column of ratings for Toy Story and the column of ratings for $x$.  Drop any rows with null values, and display the resulting dataframe.\n",
    " \n",
    "Use built-in functions to compute correlations and avoid explicit loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "correlation_table = user_ratings.loc[:, user_ratings.columns != 'Toy Story (1995)'].corrwith(user_ratings['Toy Story (1995)'], method=\"pearson\").dropna()\n",
    "correlation_table = pd.DataFrame({'title': correlation_table.index, 'Correlation': correlation_table.values})\n",
    "correlation_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the movies by descending order of correlation to find out highly correlated movies at the top. Display the 5 most highly correlated movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "correlation_table = correlation_table.sort_values(by='Correlation', ascending=False)\n",
    "correlation_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you computed correlations correctly, you will find that the recommended movies are not very well known. We can generate more popular recommendations by finding highly correlated movies that have a sensible number of ratings. \n",
    " \n",
    "Add a column to your correlation table, called `rating_counts`, which stores the number of ratings received by each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\"\"\" define rating counts data \"\"\"\n",
    "rating_counts_data = user_ratings.notnull().sum(axis=0)\n",
    "rating_counts_data = pd.DataFrame({'title':rating_counts_data.index, 'rating_counts':rating_counts_data.values})\n",
    "\n",
    "\"\"\" merge \"\"\"\n",
    "correlation_table = pd.merge(correlation_table, rating_counts_data, how = 'inner', on = 'title')\n",
    "display(correlation_table.head())\n",
    "\n",
    "\"\"\" free memory \"\"\"\n",
    "del(rating_counts_data, user_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the 5 movies with the highest correlation with Toy Story, which have strictly more than 100 ratings. Display the result below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "correlation_table[correlation_table['rating_counts'] > 100].sort_values(by='Correlation', ascending=False).head(5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
